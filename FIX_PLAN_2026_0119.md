# FIX PLAN - LIFESCORE SCORING SYSTEM

## Conversation ID: LIFESCORE-2026-0119-SCORING-AUDIT
## Date: January 19, 2026

---

## OVERVIEW

This document contains the exact code changes needed to fix the scoring system.
Port these changes to `api/evaluate.ts` from `src/services/llmEvaluators.ts`.

---

## FIX #1: Format Category Options Properly

### File: api/evaluate.ts
### Line: 216
### Current (BROKEN):
```typescript
  **CATEGORY OPTIONS (choose EXACTLY one value for each city):**
${options}`;
```

### Fixed:
```typescript
  **CATEGORY OPTIONS (choose EXACTLY one value for each city):**
${options.map(o => `    - "${o.value}": ${o.label} â†’ ${o.score} points`).join('\n')}`;
```

---

## FIX #2: Add buildEvaluationPrompt with Full Scoring Guidelines

### File: api/evaluate.ts
### Add after line 125 (after letterToScore function):

```typescript
// Authoritative sources for LLM web search
const AUTHORITATIVE_SOURCES = [
  'norml.org (cannabis laws)',
  'gunlaws.com (firearm regulations)',
  'ncsl.org (state legislation)',
  'ballotpedia.org (ballot measures)',
  'findlaw.com (legal information)',
  'justia.com (case law)',
  'state legislature websites',
  'city/county government websites'
];

// Build evaluation prompt with full scoring guidelines
function buildEvaluationPromptWithScoring(
  city1: string,
  city2: string,
  metrics: EvaluationRequest['metrics'],
  includeSearchInstructions: boolean = false
): string {
  const sourcesList = AUTHORITATIVE_SOURCES.map(s => `  - ${s}`).join('\n');

  const searchPreamble = includeSearchInstructions ? `
IMPORTANT: Use your web search capabilities to find current, accurate data about these cities' laws and regulations.

## PRIORITIZED DATA SOURCES
Search these authoritative sources FIRST:
${sourcesList}

Also search official government websites for the specific cities/regions being compared.
You MUST cite your sources in the "sources" field with actual URLs.

` : '';

  const metricsList = metrics.map(m => `
- ${m.id}: ${m.name}
  Category: ${m.categoryId}
  Description: ${m.description}
  Scoring: ${m.scoringDirection === 'higher_is_better' ? 'Higher = more freedom' : 'Lower = more freedom'}
`).join('\n');

  return `${searchPreamble}You are an expert legal analyst evaluating freedom metrics for city comparison.

## TASK
Evaluate the following metrics for two cities, providing DUAL scores:
1. **Legal Score (0-100)**: What does the law technically say? Higher = more permissive law
2. **Enforcement Score (0-100)**: How is the law actually enforced? Higher = more lenient enforcement

## CITIES TO COMPARE
- City 1: ${city1}
- City 2: ${city2}

## METRICS TO EVALUATE
${metricsList}

## OUTPUT FORMAT
Return a JSON object with this exact structure:
{
  "evaluations": [
    {
      "metricId": "metric_id_here",
      "city1LegalScore": 75,
      "city1EnforcementScore": 70,
      "city2LegalScore": 60,
      "city2EnforcementScore": 55,
      "confidence": "high",
      "reasoning": "Brief explanation with specific legal references",
      "sources": ["URL1", "URL2"]
    }
  ]
}

## SCORING GUIDELINES
- 90-100: Extremely permissive, minimal restrictions (MOST FREE)
- 70-89: Generally permissive with some limitations
- 50-69: Moderate restrictions
- 30-49: Significant restrictions
- 0-29: Highly restrictive or prohibited (LEAST FREE)

## IMPORTANT
- Be specific about laws and regulations
- Note differences between federal/national and local laws
- Consider recent changes (last 2 years)
- If uncertain, set confidence to "low" but still provide best estimate
- Enforcement score may differ significantly from legal score (e.g., law exists but rarely enforced)
- You MUST evaluate ALL ${metrics.length} metrics - do not skip any

Return ONLY the JSON object, no other text.`;
}
```

---

## FIX #3: Update Claude Evaluator

### File: api/evaluate.ts
### Function: evaluateWithClaude (around line 425)

### Add Claude-specific addendum:
```typescript
// CLAUDE-SPECIFIC ADDENDUM
const claudeAddendum = `
## CLAUDE-SPECIFIC INSTRUCTIONS
- Use the Tavily Research Report as your primary baseline for comparing ${city1} vs ${city2}
- Cross-reference with category-specific search results for detailed metrics
- You excel at nuanced legal interpretation - distinguish between law text vs enforcement reality
- For ambiguous cases, lean toward the grade that reflects lived experience over technical legality
- You MUST return evaluations for ALL ${metrics.length} metrics
`;

const prompt = tavilyContext + buildEvaluationPromptWithScoring(city1, city2, metrics, false) + claudeAddendum;
```

---

## FIX #4: Update GPT-4o Evaluator with Full System Prompt

### File: api/evaluate.ts
### Function: evaluateWithGPT4o (around line 547)

### Replace simple system message with detailed prompt:
```typescript
// GPT-4o detailed system prompt with scoring guidelines
const gptSystemPrompt = `You are an expert legal analyst comparing two cities on freedom metrics.
Use the built-in web_search tool to find current, accurate data about laws and regulations.

## SCORING SCALE (0-100)
- 90-100: Extremely permissive, minimal restrictions (most free)
- 70-89: Generally permissive with some limitations
- 50-69: Moderate restrictions
- 30-49: Significant restrictions
- 0-29: Highly restrictive or prohibited (least free)

## DUAL SCORING SYSTEM
For each metric, provide TWO scores:
1. **Legal Score**: What does the law technically say? Higher = more permissive law
2. **Enforcement Score**: How is the law actually enforced? Higher = more lenient enforcement

## IMPORTANT
- Cite every claim with actual URLs
- Note differences between federal/state/local laws
- If evidence is missing, set confidence="low" and explain why
- Return JSON exactly matching the schema provided
- You MUST evaluate ALL metrics provided - do not skip any`;

// In the API call:
messages: [
  { role: 'system', content: gptSystemPrompt },
  { role: 'user', content: prompt }
]
```

---

## FIX #5: Update Gemini Evaluator with Safety Settings

### File: api/evaluate.ts
### Function: evaluateWithGemini (around line 670)

### Add systemInstruction and safety settings:
```typescript
// Gemini system instruction
const systemInstruction = {
  parts: [{
    text: 'You are an expert legal analyst evaluating freedom metrics for city comparison. Use Google Search grounding to find current, accurate data about laws and regulations. Be factual and cite sources. You MUST evaluate ALL metrics provided.'
  }]
};

// In the API call body:
body: JSON.stringify({
  systemInstruction,  // ADD THIS
  contents: [{ parts: [{ text: prompt }] }],
  generationConfig: { maxOutputTokens: 16384, temperature: 0.3 },
  // Safety settings - allow freedom-related content
  safetySettings: [
    { category: 'HARM_CATEGORY_DANGEROUS_CONTENT', threshold: 'BLOCK_ONLY_HIGH' },
    { category: 'HARM_CATEGORY_HATE_SPEECH', threshold: 'BLOCK_ONLY_HIGH' },
    { category: 'HARM_CATEGORY_HARASSMENT', threshold: 'BLOCK_ONLY_HIGH' },
    { category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT', threshold: 'BLOCK_ONLY_HIGH' }
  ],
  tools: [{
    google_search: {}
  }]
})
```

---

## FIX #6: Update Grok Evaluator

### File: api/evaluate.ts
### Function: evaluateWithGrok (around line 732)

### Update system message:
```typescript
messages: [
  {
    role: 'system',
    content: `You are an expert legal analyst evaluating freedom metrics. Use your real-time web search to find current laws and regulations.

## SCORING SCALE (0-100)
- 90-100: Extremely permissive, minimal restrictions (most free)
- 70-89: Generally permissive with some limitations
- 50-69: Moderate restrictions
- 30-49: Significant restrictions
- 0-29: Highly restrictive or prohibited (least free)

You MUST evaluate ALL metrics provided and return valid JSON.`
  },
  { role: 'user', content: prompt }
],
search: true  // Grok native search
```

---

## FIX #7: Update Perplexity Evaluator - Remove Broken JSON Schema

### File: api/evaluate.ts
### Function: evaluateWithPerplexity (around line 799)

### Option A: Remove strict JSON schema, let it follow prompt
```typescript
body: JSON.stringify({
  model: 'sonar-reasoning-pro',
  messages: [
    {
      role: 'system',
      content: `You are an expert legal analyst evaluating freedom metrics. Use your web search to find current laws.

## SCORING SCALE (0-100)
- 90-100: Extremely permissive (most free)
- 70-89: Generally permissive
- 50-69: Moderate restrictions
- 30-49: Significant restrictions
- 0-29: Highly restrictive (least free)

Return ONLY valid JSON matching the exact format requested. Evaluate ALL metrics.`
    },
    { role: 'user', content: prompt }
  ],
  max_tokens: 16384,
  temperature: 0.3,
  return_citations: true
  // REMOVED: response_format with broken schema
})
```

---

## FIX #8: Add Logging to parseResponse

### File: api/evaluate.ts
### Function: parseResponse (around line 263)

### Add logging to track what LLMs return:
```typescript
function parseResponse(content: string, provider: LLMProvider): MetricScore[] {
  try {
    // Log first 500 chars of raw response for debugging
    console.log(`[PARSE] ${provider} raw response (first 500):`, content.substring(0, 500));

    // ... existing parsing code ...

    const parsed = JSON.parse(jsonStr) as { evaluations?: ParsedEvaluation[] };

    // Log what format was detected
    const hasCategories = parsed.evaluations?.some(e => e.city1Category && e.city2Category);
    const hasLetters = parsed.evaluations?.some(e => e.city1Legal || e.city2Legal);
    const hasNumbers = parsed.evaluations?.some(e => typeof e.city1LegalScore === 'number');
    console.log(`[PARSE] ${provider} format: categories=${hasCategories}, letters=${hasLetters}, numbers=${hasNumbers}`);
    console.log(`[PARSE] ${provider} returned ${parsed.evaluations?.length || 0} evaluations`);

    // ... rest of parsing ...
```

---

## TESTING CHECKLIST

After implementing fixes:

1. [ ] Test Claude Sonnet - verify 0-100 scores returned
2. [ ] Test GPT-4o - verify 0-100 scores returned
3. [ ] Test Gemini - verify safety settings work, 0-100 scores
4. [ ] Test Grok - verify 0-100 scores (not 25 increments)
5. [ ] Test Perplexity - verify 0-100 scores (not 0 or 1)
6. [ ] Verify ALL 15-25 metrics returned per category (not 25%)
7. [ ] Compare Austin vs Denver - verify DIFFERENT scores
8. [ ] Compare Denver vs Austin - verify cache order correct

---

## DEPLOYMENT ORDER

1. Commit fixes to api/evaluate.ts
2. Push to GitHub
3. Vercel auto-deploys
4. Test each LLM one at a time
5. Verify in Vercel logs that correct format is returned
6. Run full comparison test

---

## ROLLBACK PLAN

If fixes cause issues:
```bash
git revert HEAD  # Revert latest commit
git push origin main
```

Or restore to last known working state:
```bash
git checkout bf58c50 -- api/evaluate.ts  # Before Phase 2 changes
git push origin main
```

---

## FILES TO MODIFY

| File | Changes |
|------|---------|
| api/evaluate.ts | All 8 fixes above |
| api/shared/metrics.ts | No changes needed |
| vercel.json | No changes needed |

---

## ESTIMATED TIME

- Fix #1 (options formatting): 2 minutes
- Fix #2 (buildEvaluationPromptWithScoring): 5 minutes
- Fix #3-7 (LLM evaluators): 15 minutes
- Fix #8 (logging): 3 minutes
- Testing: 30 minutes

Total: ~1 hour

---

## APPROVAL REQUIRED

Before implementing these fixes, user must approve:
1. The overall approach (0-100 numeric scoring)
2. Removal of Perplexity strict JSON schema
3. Adding detailed system prompts to all LLMs
